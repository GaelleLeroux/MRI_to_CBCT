{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from nets.cut import Cut\n",
    "from pytorch_lightning import Trainer\n",
    "from data_loader_gaelle import ConcatDataset,ImageDataset, LotusDataModule, ConcatDataModule, LotusTrainTransforms2\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from callbackss import logger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "from pytorch_lightning.strategies.ddp import DDPStrategy\n",
    "\n",
    "from monai.transforms import (  \n",
    "    LoadImaged,\n",
    "    Compose,\n",
    "    Resize,\n",
    "    RandZoomd,\n",
    "    RandRotated,\n",
    "    RandAffined,\n",
    "    ToTensord\n",
    ")   \n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'img_fn', 'group', 'ignore_size_info', 'label'], dtype='object')\n",
      "   index                  img_fn group  ignore_size_info  label\n",
      "0      0  train/B040_cropped.nii     .                 0      1\n",
      "1      1  train/B041_cropped.nii     .                 0      2\n",
      "2      2  train/M001_cropped.nii     .                 0      3\n",
      "3      3  train/M002_cropped.nii     .                 0      4\n",
      "4      4  train/M003_cropped.nii     .                 0      5\n",
      "df_train_cbct :      index                  img_fn group  ignore_size_info  label\n",
      "0       0  train/B040_cropped.nii     .                 0      1\n",
      "1       1  train/B041_cropped.nii     .                 0      2\n",
      "2       2  train/M001_cropped.nii     .                 0      3\n",
      "3       3  train/M002_cropped.nii     .                 0      4\n",
      "4       4  train/M003_cropped.nii     .                 0      5\n",
      "..    ...                     ...   ...               ...    ...\n",
      "59     59  train/M061_cropped.nii     .                 0     60\n",
      "60     60  train/M062_cropped.nii     .                 0     61\n",
      "61     61  train/M066_cropped.nii     .                 0     62\n",
      "62     62  train/M067_cropped.nii     .                 0     63\n",
      "63     63  train/M073_cropped.nii     .                 0     64\n",
      "\n",
      "[64 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train_cbct = pd.read_csv(\"/home/luciacev/Documents/Gaelle/Data/MultimodelReg_2/MRI_to_CBCT/training_CBCT/train.csv\") \n",
    "df_val_cbct = pd.read_csv(\"/home/luciacev/Documents/Gaelle/Data/MultimodelReg_2/MRI_to_CBCT/training_CBCT/valid.csv\")  \n",
    "df_test_cbct = pd.read_csv(\"/home/luciacev/Documents/Gaelle/Data/MultimodelReg_2/MRI_to_CBCT/training_CBCT/test.csv\")\n",
    "\n",
    "df_train_mri = pd.read_csv(\"/home/luciacev/Documents/Gaelle/Data/MultimodelReg_2/MRI_to_CBCT/training_CBCT/train.csv\")\n",
    "df_val_mri = pd.read_csv(\"/home/luciacev/Documents/Gaelle/Data/MultimodelReg_2/MRI_to_CBCT/training_CBCT/valid.csv\")   \n",
    "df_test_mri = pd.read_csv(\"/home/luciacev/Documents/Gaelle/Data/MultimodelReg_2/MRI_to_CBCT/training_CBCT/test.csv\") \n",
    "\n",
    "\n",
    "print(df_train_mri.columns)  # Affiche les noms de colonnes du DataFrame\n",
    "print(df_train_mri.head())   # Affiche les premières lignes pour vérifier les données\n",
    "\n",
    "\n",
    "print(\"df_train_cbct : \",df_train_cbct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [   \n",
    "        # EnsureChannelFirstd(keys=['img', 'seg'], channel_dim=-1),\n",
    "        LoadImaged(keys=['img_mri', 'img_cbct']),\n",
    "        RandZoomd(keys=['img_mri', 'img_cbct'], min_zoom=0.8, max_zoom=1.1, mode=['area', 'nearest'], prob=0.9, padding_mode='constant'),\n",
    "        RandRotated(keys=['img_mri', 'img_cbct'], range_x=math.pi, mode=['bilinear', 'nearest'], prob=1.0),\n",
    "        RandAffined(keys=['img_mri', 'img_cbct'], prob=0.8, shear_range=(0.1, 0.1), mode=['bilinear', 'nearest'], padding_mode='zeros'),\n",
    "        ToTensord(keys=['img_mri', 'img_cbct'])\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat_data :  <data_loader_gaelle.ConcatDataModule object at 0x79ff635eaf40>\n"
     ]
    }
   ],
   "source": [
    "train_transform_mri = LotusTrainTransforms2()\n",
    "valid_transform_mri = LotusTrainTransforms2()\n",
    "MRI_data = LotusDataModule(df_train_mri, df_val_mri, df_test_mri, mount_point=\".\", batch_size=2, num_workers=4, img_column=\"img_fn\", seg_column=\"seg_path\", train_transform=train_transform_mri, valid_transform=valid_transform_mri, test_transform=valid_transform_mri, drop_last=False)\n",
    "\n",
    "MRI_data.setup()\n",
    "\n",
    "\n",
    "train_transform_cbct = LotusTrainTransforms2()\n",
    "valid_transform_cbct = LotusTrainTransforms2()\n",
    "CBCT_data = LotusDataModule(df_train_cbct, df_val_cbct, df_test_cbct, mount_point=\".\", batch_size=2, num_workers=4, img_column=\"img_path\", seg_column=\"seg_path\", train_transform=train_transform_cbct, valid_transform=valid_transform_cbct, test_transform=valid_transform_cbct, drop_last=False)\n",
    "CBCT_data.setup()\n",
    "\n",
    "concat_data = ConcatDataModule(MRI_data.train_ds, MRI_data.val_ds, CBCT_data.train_ds, CBCT_data.val_ds, batch_size=2, num_workers=4)\n",
    "concat_data.setup()\n",
    "print(\"concat_data : \",concat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'img_path'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/luciacev/Documents/Gaelle/MRI_to_CBCT/mri_to_cbct/data_loader_gaelle.py\", line 52, in __getitem__\n    return tuple(self.check_len(d, i) for d in self.datasets)\n  File \"/home/luciacev/Documents/Gaelle/MRI_to_CBCT/mri_to_cbct/data_loader_gaelle.py\", line 52, in <genexpr>\n    return tuple(self.check_len(d, i) for d in self.datasets)\n  File \"/home/luciacev/Documents/Gaelle/MRI_to_CBCT/mri_to_cbct/data_loader_gaelle.py\", line 68, in check_len\n    return d[i]\n  File \"/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/monai/data/dataset.py\", line 112, in __getitem__\n    return self._transform(index)\n  File \"/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/monai/data/dataset.py\", line 97, in _transform\n    data_i = self.data[index]\n  File \"/home/luciacev/Documents/Gaelle/MRI_to_CBCT/mri_to_cbct/data_loader_gaelle.py\", line 208, in __getitem__\n    img_path = os.path.join(self.mount_point, self.df.iloc[idx][self.img_column])\n  File \"/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/pandas/core/series.py\", line 1121, in __getitem__\n    return self._get_value(key)\n  File \"/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/pandas/core/series.py\", line 1237, in _get_value\n    loc = self.index.get_loc(label)\n  File \"/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    raise KeyError(key) from err\nKeyError: 'img_path'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m concat_data\u001b[38;5;241m.\u001b[39mtrain_dataloader():\n\u001b[1;32m      2\u001b[0m     images_mri, images_cbct \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_mri\u001b[39m\u001b[38;5;124m'\u001b[39m], batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_cbct\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m     segs_mri, segs_cbct \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseg_mri\u001b[39m\u001b[38;5;124m'\u001b[39m], batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseg_cbct\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/APP/miniconda3/envs/pl/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/APP/miniconda3/envs/pl/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/APP/miniconda3/envs/pl/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/APP/miniconda3/envs/pl/lib/python3.9/site-packages/torch/_utils.py:705\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'img_path'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/luciacev/Documents/Gaelle/MRI_to_CBCT/mri_to_cbct/data_loader_gaelle.py\", line 52, in __getitem__\n    return tuple(self.check_len(d, i) for d in self.datasets)\n  File \"/home/luciacev/Documents/Gaelle/MRI_to_CBCT/mri_to_cbct/data_loader_gaelle.py\", line 52, in <genexpr>\n    return tuple(self.check_len(d, i) for d in self.datasets)\n  File \"/home/luciacev/Documents/Gaelle/MRI_to_CBCT/mri_to_cbct/data_loader_gaelle.py\", line 68, in check_len\n    return d[i]\n  File \"/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/monai/data/dataset.py\", line 112, in __getitem__\n    return self._transform(index)\n  File \"/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/monai/data/dataset.py\", line 97, in _transform\n    data_i = self.data[index]\n  File \"/home/luciacev/Documents/Gaelle/MRI_to_CBCT/mri_to_cbct/data_loader_gaelle.py\", line 208, in __getitem__\n    img_path = os.path.join(self.mount_point, self.df.iloc[idx][self.img_column])\n  File \"/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/pandas/core/series.py\", line 1121, in __getitem__\n    return self._get_value(key)\n  File \"/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/pandas/core/series.py\", line 1237, in _get_value\n    loc = self.index.get_loc(label)\n  File \"/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    raise KeyError(key) from err\nKeyError: 'img_path'\n"
     ]
    }
   ],
   "source": [
    "for batch in concat_data.train_dataloader():\n",
    "    images_mri, images_cbct = batch['img_mri'], batch['img_cbct']\n",
    "    segs_mri, segs_cbct = batch['seg_mri'], batch['seg_cbct']\n",
    "    \n",
    "    # Afficher les tailles des tensors\n",
    "    print(\"Images MRI:\", images_mri.shape)\n",
    "    print(\"Images CBCT:\", images_cbct.shape)\n",
    "    print(\"Segs MRI:\", segs_mri.shape)\n",
    "    print(\"Segs CBCT:\", segs_cbct.shape)\n",
    "    \n",
    "    # Afficher quelques exemples d'images et de segments\n",
    "    num_examples = min(2, images_mri.shape[0])\n",
    "    for i in range(num_examples):\n",
    "        # Afficher les images MRI et CBCT\n",
    "        img_mri = images_mri[i]\n",
    "        img_cbct = images_cbct[i]\n",
    "        # Afficher les segments MRI et CBCT\n",
    "        seg_mri = segs_mri[i]\n",
    "        seg_cbct = segs_cbct[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath='/home/luciacev/Documents/Gaelle/Data/MultimodelReg_2/MRI_to_CBCT/output_train/',\n",
    "            filename='{epoch}-{val_loss:.2f}',\n",
    "            save_top_k=2,\n",
    "            monitor='val_loss'\n",
    "        )\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=30, verbose=True, mode=\"min\")\n",
    "\n",
    "callbacks=[early_stop_callback, checkpoint_callback]\n",
    "neptune_logger = None\n",
    "\n",
    "os.environ['NEPTUNE_API_TOKEN'] = 'eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI4ZDQ0NTI4Yi03ZWI3LTRiN2UtODAwMi04MThhYzAwNWJhZDgifQ=='\n",
    "\n",
    "neptune_logger = NeptuneLogger(\n",
    "    project='gaellel/MRICBCT',\n",
    "    tags=[\"v1\"],\n",
    "    api_key=os.environ['NEPTUNE_API_TOKEN']\n",
    ")\n",
    "\n",
    "LOGGER = getattr(logger, \"CutLogger\")    \n",
    "image_logger = LOGGER(log_steps=100)\n",
    "callbacks.append(image_logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MisconfigurationException",
     "evalue": "`Trainer(strategy=<pytorch_lightning.strategies.ddp.DDPStrategy object at 0x79ff635400a0>)` is not compatible with an interactive environment. Run your code as a script, or choose a notebook-compatible strategy: `Trainer(strategy='ddp_notebook')`. In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneptune_logger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_every_n_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDDPStrategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind_unused_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreload_dataloaders_every_n_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# detect_anomaly=True\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/APP/miniconda3/envs/pl/lib/python3.9/site-packages/pytorch_lightning/utilities/argparse.py:70\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/APP/miniconda3/envs/pl/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:401\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, accelerator, strategy, devices, num_nodes, precision, logger, callbacks, fast_dev_run, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, overfit_batches, val_check_interval, check_val_every_n_epoch, num_sanity_val_steps, log_every_n_steps, enable_checkpointing, enable_progress_bar, enable_model_summary, accumulate_grad_batches, gradient_clip_val, gradient_clip_algorithm, deterministic, benchmark, inference_mode, use_distributed_sampler, profiler, detect_anomaly, barebones, plugins, sync_batchnorm, reload_dataloaders_every_n_epochs, default_root_dir)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# init connectors\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector \u001b[38;5;241m=\u001b[39m _DataConnector(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 401\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerator_connector \u001b[38;5;241m=\u001b[39m \u001b[43m_AcceleratorConnector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync_batchnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync_batchnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbenchmark\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbenchmark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_distributed_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_distributed_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplugins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger_connector \u001b[38;5;241m=\u001b[39m _LoggerConnector(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_connector \u001b[38;5;241m=\u001b[39m _CallbackConnector(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/APP/miniconda3/envs/pl/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:166\u001b[0m, in \u001b[0;36m_AcceleratorConnector.__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, sync_batchnorm, benchmark, use_distributed_sampler, deterministic)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_and_init_precision()\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# 6. Instantiate Strategy - Part 2\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_init_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/APP/miniconda3/envs/pl/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:614\u001b[0m, in \u001b[0;36m_AcceleratorConnector._lazy_init_strategy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_configure_launcher()\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _IS_INTERACTIVE \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mis_interactive_compatible:\n\u001b[0;32m--> 614\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    615\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Trainer(strategy=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy_flag\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m)` is not compatible with an interactive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    616\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m environment. Run your code as a script, or choose a notebook-compatible strategy:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    617\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `Trainer(strategy=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mddp_notebook\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    618\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m In case you are spawning processes yourself, make sure to include the Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    619\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m creation inside the worker function.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    620\u001b[0m     )\n\u001b[1;32m    622\u001b[0m \u001b[38;5;66;03m# TODO: should be moved to _check_strategy_and_fallback().\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;66;03m# Current test check precision first, so keep this check here to meet error order\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, XLAAccelerator) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, (SingleDeviceXLAStrategy, XLAStrategy)\n\u001b[1;32m    626\u001b[0m ):\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: `Trainer(strategy=<pytorch_lightning.strategies.ddp.DDPStrategy object at 0x79ff635400a0>)` is not compatible with an interactive environment. Run your code as a script, or choose a notebook-compatible strategy: `Trainer(strategy='ddp_notebook')`. In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function."
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    logger=neptune_logger,\n",
    "    log_every_n_steps=100,\n",
    "    max_epochs=200,\n",
    "    max_steps=-1,\n",
    "    callbacks=callbacks,\n",
    "    accelerator='gpu', \n",
    "    devices=torch.cuda.device_count(),\n",
    "    strategy=DDPStrategy(find_unused_parameters=False),\n",
    "    reload_dataloaders_every_n_epochs=1\n",
    "    # detect_anomaly=True\n",
    ")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
