{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from nets.cut import Cut\n",
    "from pytorch_lightning import Trainer\n",
    "# from data_loader_gaelle import ConcatDataset,ImageDataset,LotusDataModule, ConcatDataModule, LotusTrainTransforms2\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from callbackss import logger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "from pytorch_lightning.strategies.ddp import DDPStrategy\n",
    "\n",
    "from monai.transforms import (  \n",
    "    LoadImaged,\n",
    "    Compose,\n",
    "    Resize,\n",
    "    RandZoomd,\n",
    "    RandRotated,\n",
    "    RandAffined,\n",
    "    ToTensord\n",
    ")   \n",
    "import math\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from PIL import Image\n",
    "# import nrrd\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import monai\n",
    "from monai.transforms import (  \n",
    "    LoadImaged,\n",
    "    Compose,\n",
    "    Resize,\n",
    "    RandZoomd,\n",
    "    RandRotated,\n",
    "    RandAffined,\n",
    "    ToTensord\n",
    ")   \n",
    "import math\n",
    "\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'img_fn', 'group', 'ignore_size_info', 'label'], dtype='object')\n",
      "   index                  img_fn group  ignore_size_info  label\n",
      "0      0  train/B040_cropped.nii     .                 0      1\n",
      "1      1  train/B041_cropped.nii     .                 0      2\n",
      "2      2  train/M001_cropped.nii     .                 0      3\n",
      "3      3  train/M002_cropped.nii     .                 0      4\n",
      "4      4  train/M003_cropped.nii     .                 0      5\n",
      "df_train_cbct :      index                  img_fn group  ignore_size_info  label\n",
      "0       0  train/B040_cropped.nii     .                 0      1\n",
      "1       1  train/B041_cropped.nii     .                 0      2\n",
      "2       2  train/M001_cropped.nii     .                 0      3\n",
      "3       3  train/M002_cropped.nii     .                 0      4\n",
      "4       4  train/M003_cropped.nii     .                 0      5\n",
      "..    ...                     ...   ...               ...    ...\n",
      "59     59  train/M061_cropped.nii     .                 0     60\n",
      "60     60  train/M062_cropped.nii     .                 0     61\n",
      "61     61  train/M066_cropped.nii     .                 0     62\n",
      "62     62  train/M067_cropped.nii     .                 0     63\n",
      "63     63  train/M073_cropped.nii     .                 0     64\n",
      "\n",
      "[64 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train_cbct = pd.read_csv(\"/home/luciacev/Documents/Gaelle/Data/MultimodelReg_2/MRI_to_CBCT/training_CBCT/train.csv\") \n",
    "df_val_cbct = pd.read_csv(\"/home/luciacev/Documents/Gaelle/Data/MultimodelReg_2/MRI_to_CBCT/training_CBCT/valid.csv\")  \n",
    "df_test_cbct = pd.read_csv(\"/home/luciacev/Documents/Gaelle/Data/MultimodelReg_2/MRI_to_CBCT/training_CBCT/test.csv\")\n",
    "\n",
    "df_train_mri = pd.read_csv(\"/home/luciacev/Documents/Gaelle/Data/MultimodelReg_2/MRI_to_CBCT/training_CBCT/train.csv\")\n",
    "df_val_mri = pd.read_csv(\"/home/luciacev/Documents/Gaelle/Data/MultimodelReg_2/MRI_to_CBCT/training_CBCT/valid.csv\")   \n",
    "df_test_mri = pd.read_csv(\"/home/luciacev/Documents/Gaelle/Data/MultimodelReg_2/MRI_to_CBCT/training_CBCT/test.csv\") \n",
    "\n",
    "\n",
    "print(df_train_mri.columns)  # Affiche les noms de colonnes du DataFrame\n",
    "print(df_train_mri.head())   # Affiche les premières lignes pour vérifier les données\n",
    "\n",
    "\n",
    "print(\"df_train_cbct : \",df_train_cbct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [   \n",
    "        # EnsureChannelFirstd(keys=['img', 'seg'], channel_dim=-1),\n",
    "        LoadImaged(keys=['img_mri', 'img_cbct']),\n",
    "        RandZoomd(keys=['img_mri', 'img_cbct'], min_zoom=0.8, max_zoom=1.1, mode=['area', 'nearest'], prob=0.9, padding_mode='constant'),\n",
    "        RandRotated(keys=['img_mri', 'img_cbct'], range_x=math.pi, mode=['bilinear', 'nearest'], prob=1.0),\n",
    "        RandAffined(keys=['img_mri', 'img_cbct'], prob=0.8, shear_range=(0.1, 0.1), mode=['bilinear', 'nearest'], padding_mode='zeros'),\n",
    "        ToTensord(keys=['img_mri', 'img_cbct'])\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LotusTrainTransforms2:\n",
    "    def __init__(self, height: int = 256):\n",
    "\n",
    "        # image augmentation functions\n",
    "        self.train_transform = Compose(\n",
    "            [   \n",
    "            LoadImaged(keys=['img_mri', 'img_cbct']),\n",
    "            RandZoomd(keys=['img_mri', 'img_cbct'], min_zoom=0.8, max_zoom=1.1, mode=['area', 'nearest'], prob=0.9, padding_mode='constant'),\n",
    "            RandRotated(keys=['img_mri', 'img_cbct'], range_x=math.pi, mode=['bilinear', 'nearest'], prob=1.0),\n",
    "            RandAffined(keys=['img_mri', 'img_cbct'], prob=0.8, shear_range=(0.1, 0.1), mode=['bilinear', 'nearest'], padding_mode='zeros'),\n",
    "            ToTensord(keys=['img_mri', 'img_cbct'])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __call__(self, inp):\n",
    "        return self.train_transform(inp) \n",
    "   \n",
    "\n",
    "class LotusDataset(Dataset):\n",
    "    def __init__(self, df, mount_point = \"./\", img_column=\"img_path\", seg_column=None):\n",
    "        self.df = df\n",
    "        self.mount_point = mount_point\n",
    "        self.img_column = img_column\n",
    "        self.seg_column = seg_column\n",
    "        \n",
    "        self.loader = LoadImaged(keys=[\"img_mri\", \"img_cbct\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path = os.path.join(self.mount_point, self.df.iloc[idx][self.img_column])\n",
    "        \n",
    "\n",
    "        d = {\"img_mri\": img_path, \"img_cbct\": img_path}\n",
    "        \n",
    "        \n",
    "        d = self.loader(d)\n",
    "        \n",
    "        return d\n",
    "    \n",
    "class LotusDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, df_train, df_val, df_test, mount_point=\"./\", batch_size=256, num_workers=4, img_column=\"img_path\", train_transform=None, valid_transform=None, test_transform=None, drop_last=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df_train = df_train\n",
    "        self.df_val = df_val\n",
    "        self.df_test = df_test\n",
    "        self.mount_point = mount_point\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.img_column = img_column        \n",
    "        self.train_transform = train_transform\n",
    "        self.valid_transform = valid_transform\n",
    "        self.test_transform = test_transform\n",
    "        self.drop_last=drop_last        \n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        self.train_ds = monai.data.Dataset(data=LotusDataset(self.df_train, self.mount_point, img_column=self.img_column), transform=self.train_transform)\n",
    "        self.val_ds = monai.data.Dataset(data=LotusDataset(self.df_val, self.mount_point, img_column=self.img_column), transform=self.valid_transform)\n",
    "        self.test_ds = monai.data.Dataset(data=LotusDataset(self.df_test, self.mount_point, img_column=self.img_column), transform=self.test_transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_size=self.batch_size, num_workers=self.num_workers, persistent_workers=True, pin_memory=True, drop_last=self.drop_last, shuffle=True, prefetch_factor=2)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size=self.batch_size, num_workers=self.num_workers, persistent_workers=False, pin_memory=True, drop_last=self.drop_last)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_ds, batch_size=self.batch_size, num_workers=self.num_workers, persistent_workers=True, pin_memory=True, drop_last=self.drop_last)\n",
    "    \n",
    "class ConcatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, *datasets, use_max=True):\n",
    "        self.datasets = datasets\n",
    "        self.use_max = use_max\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # print(f\"Fetching index: {i}\") #debug\n",
    "        # for d in self.datasets:\n",
    "            # print(f\"Dataset length: {len(d)}\") #debug\n",
    "        return tuple(self.check_len(d, i) for d in self.datasets)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.use_max:\n",
    "            return max(len(d) for d in self.datasets)\n",
    "        return min(len(d) for d in self.datasets)\n",
    "\n",
    "    def shuffle(self):\n",
    "        for d in self.datasets:\n",
    "            if isinstance(d, monai.data.Dataset):                \n",
    "                d.data.df = d.data.df.sample(frac=1.0).reset_index(drop=True)                \n",
    "            else:\n",
    "                d.df = d.df.sample(frac=1.0).reset_index(drop=True)\n",
    "\n",
    "    def check_len(self, d, i):\n",
    "        if i < len(d):\n",
    "            return d[i]\n",
    "        else:\n",
    "            j = i % len(d)\n",
    "            return d[j]\n",
    "    \n",
    "class ConcatDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, datasetA_train, datasetA_val, datasetB_train, datasetB_val, batch_size=8, num_workers=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.datasetA_train = datasetA_train\n",
    "        self.datasetB_train = datasetB_train\n",
    "\n",
    "        self.datasetA_val = datasetA_val\n",
    "        self.datasetB_val = datasetB_val\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders        \n",
    "        self.train_ds =  ConcatDataset(self.datasetA_train, self.datasetB_train)\n",
    "        self.val_ds = ConcatDataset(self.datasetA_val, self.datasetB_val)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        print(\"train_ds : \",self.train_ds)\n",
    "        \n",
    "        self.train_ds.shuffle()\n",
    "        return DataLoader(self.train_ds, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=True, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat_data :  <__main__.ConcatDataModule object at 0x7ef39c163700>\n",
      "oui\n"
     ]
    }
   ],
   "source": [
    "train_transform_mri = LotusTrainTransforms2()\n",
    "valid_transform_mri = LotusTrainTransforms2()\n",
    "MRI_data = LotusDataModule(df_train_mri, df_val_mri, df_test_mri, mount_point=\"/home/luciacev/Documents/Gaelle/Data/MultimodelReg_2/MRI_to_CBCT/training_MRI/\", batch_size=2, num_workers=4, img_column=\"img_fn\", train_transform=train_transform_mri, valid_transform=valid_transform_mri, test_transform=valid_transform_mri, drop_last=False)\n",
    "\n",
    "MRI_data.setup()\n",
    "\n",
    "train_transform_cbct = LotusTrainTransforms2()\n",
    "valid_transform_cbct = LotusTrainTransforms2()\n",
    "CBCT_data = LotusDataModule(df_train_cbct, df_val_cbct, df_test_cbct, mount_point=\"/home/luciacev/Documents/Gaelle/Data/MultimodelReg_2/MRI_to_CBCT/training_CBCT/\", batch_size=2, num_workers=4, img_column=\"img_fn\", train_transform=train_transform_cbct, valid_transform=valid_transform_cbct, test_transform=valid_transform_cbct, drop_last=False)\n",
    "CBCT_data.setup()\n",
    "\n",
    "concat_data = ConcatDataModule(MRI_data.train_ds, MRI_data.val_ds, CBCT_data.train_ds, CBCT_data.val_ds, batch_size=2, num_workers=4)\n",
    "concat_data.setup()\n",
    "print(\"concat_data : \",concat_data)\n",
    "print(\"oui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1\n",
      "train_ds :  <__main__.ConcatDataset object at 0x7ef27b2f3fd0>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39mcuda)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m concat_data\u001b[38;5;241m.\u001b[39mtrain_dataloader():\n\u001b[1;32m      3\u001b[0m     images_mri, images_cbct \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_mri\u001b[39m\u001b[38;5;124m'\u001b[39m], batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_cbct\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Afficher les tailles des tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/APP/miniconda3/envs/pl/lib/python3.9/site-packages/torch/utils/data/dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/APP/miniconda3/envs/pl/lib/python3.9/site-packages/torch/utils/data/dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/APP/miniconda3/envs/pl/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1055\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     current_device \u001b[38;5;241m=\u001b[39m custom_device_mod\u001b[38;5;241m.\u001b[39mcurrent_device()\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1055\u001b[0m     current_device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# choose cuda for default\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m pin_memory_thread \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mThread(\n\u001b[1;32m   1057\u001b[0m     target\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39m_pin_memory_loop,\n\u001b[1;32m   1058\u001b[0m     args\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_result_queue, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_queue,\n\u001b[1;32m   1059\u001b[0m           current_device,\n\u001b[1;32m   1060\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread_done_event, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device))\n\u001b[1;32m   1061\u001b[0m pin_memory_thread\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/APP/miniconda3/envs/pl/lib/python3.9/site-packages/torch/cuda/__init__.py:778\u001b[0m, in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_device\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    777\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[0;32m~/APP/miniconda3/envs/pl/lib/python3.9/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)\n",
    "for batch in concat_data.train_dataloader():\n",
    "    images_mri, images_cbct = batch['img_mri'], batch['img_cbct']\n",
    "    \n",
    "    # Afficher les tailles des tensors\n",
    "    print(\"9\"*50)\n",
    "    print(\"Images MRI:\", images_mri.shape)\n",
    "    print(\"Images CBCT:\", images_cbct.shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "12.1\n",
      "CUDA n'est pas disponible sur cet environnement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luciacev/APP/miniconda3/envs/pl/lib/python3.9/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Remplacez l'index par celui de votre GPU si nécessaire\n",
    "gpu_index = 0\n",
    "\n",
    "# Définir la variable d'environnement CUDA_VISIBLE_DEVICES\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_index)\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "\n",
    "# Vérifier si CUDA est disponible\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(torch.version.cuda)\n",
    "\n",
    "if cuda_available:\n",
    "    # Vérifier le nombre de GPU disponibles\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(\"num_gpus : \",num_gpus)\n",
    "\n",
    "    # Afficher des informations sur chaque GPU disponible\n",
    "    for i in range(num_gpus):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "\n",
    "    # Afficher le GPU actuellement utilisé par PyTorch\n",
    "    current_device = torch.cuda.current_device()\n",
    "    print(f\"GPU actuel: {torch.cuda.get_device_name(current_device)}\")\n",
    "\n",
    "    # Afficher la version de CUDA\n",
    "    cuda_version = torch.version.cuda\n",
    "    print(f\"Version CUDA: {cuda_version}\")\n",
    "else:\n",
    "    print(\"CUDA n'est pas disponible sur cet environnement.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath='/home/luciacev/Documents/Gaelle/Data/MultimodelReg_2/MRI_to_CBCT/output_train/',\n",
    "            filename='{epoch}-{val_loss:.2f}',\n",
    "            save_top_k=2,\n",
    "            monitor='val_loss'\n",
    "        )\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=30, verbose=True, mode=\"min\")\n",
    "\n",
    "callbacks=[early_stop_callback, checkpoint_callback]\n",
    "neptune_logger = None\n",
    "\n",
    "os.environ['NEPTUNE_API_TOKEN'] = 'eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI4ZDQ0NTI4Yi03ZWI3LTRiN2UtODAwMi04MThhYzAwNWJhZDgifQ=='\n",
    "\n",
    "neptune_logger = NeptuneLogger(\n",
    "    project='gaellel/MRICBCT',\n",
    "    tags=[\"v1\"],\n",
    "    api_key=os.environ['NEPTUNE_API_TOKEN']\n",
    ")\n",
    "\n",
    "LOGGER = getattr(logger, \"CutLogger\")    \n",
    "image_logger = LOGGER(log_steps=100)\n",
    "callbacks.append(image_logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MisconfigurationException",
     "evalue": "`Trainer(strategy=<pytorch_lightning.strategies.ddp.DDPStrategy object at 0x79ff635400a0>)` is not compatible with an interactive environment. Run your code as a script, or choose a notebook-compatible strategy: `Trainer(strategy='ddp_notebook')`. In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneptune_logger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_every_n_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDDPStrategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind_unused_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreload_dataloaders_every_n_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# detect_anomaly=True\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/APP/miniconda3/envs/pl/lib/python3.9/site-packages/pytorch_lightning/utilities/argparse.py:70\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/APP/miniconda3/envs/pl/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:401\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, accelerator, strategy, devices, num_nodes, precision, logger, callbacks, fast_dev_run, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, overfit_batches, val_check_interval, check_val_every_n_epoch, num_sanity_val_steps, log_every_n_steps, enable_checkpointing, enable_progress_bar, enable_model_summary, accumulate_grad_batches, gradient_clip_val, gradient_clip_algorithm, deterministic, benchmark, inference_mode, use_distributed_sampler, profiler, detect_anomaly, barebones, plugins, sync_batchnorm, reload_dataloaders_every_n_epochs, default_root_dir)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# init connectors\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector \u001b[38;5;241m=\u001b[39m _DataConnector(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 401\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerator_connector \u001b[38;5;241m=\u001b[39m \u001b[43m_AcceleratorConnector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync_batchnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync_batchnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbenchmark\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbenchmark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_distributed_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_distributed_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplugins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger_connector \u001b[38;5;241m=\u001b[39m _LoggerConnector(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_connector \u001b[38;5;241m=\u001b[39m _CallbackConnector(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/APP/miniconda3/envs/pl/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:166\u001b[0m, in \u001b[0;36m_AcceleratorConnector.__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, sync_batchnorm, benchmark, use_distributed_sampler, deterministic)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_and_init_precision()\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# 6. Instantiate Strategy - Part 2\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_init_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/APP/miniconda3/envs/pl/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:614\u001b[0m, in \u001b[0;36m_AcceleratorConnector._lazy_init_strategy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_configure_launcher()\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _IS_INTERACTIVE \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mis_interactive_compatible:\n\u001b[0;32m--> 614\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    615\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Trainer(strategy=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy_flag\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m)` is not compatible with an interactive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    616\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m environment. Run your code as a script, or choose a notebook-compatible strategy:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    617\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `Trainer(strategy=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mddp_notebook\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    618\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m In case you are spawning processes yourself, make sure to include the Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    619\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m creation inside the worker function.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    620\u001b[0m     )\n\u001b[1;32m    622\u001b[0m \u001b[38;5;66;03m# TODO: should be moved to _check_strategy_and_fallback().\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;66;03m# Current test check precision first, so keep this check here to meet error order\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, XLAAccelerator) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, (SingleDeviceXLAStrategy, XLAStrategy)\n\u001b[1;32m    626\u001b[0m ):\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: `Trainer(strategy=<pytorch_lightning.strategies.ddp.DDPStrategy object at 0x79ff635400a0>)` is not compatible with an interactive environment. Run your code as a script, or choose a notebook-compatible strategy: `Trainer(strategy='ddp_notebook')`. In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function."
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    logger=neptune_logger,\n",
    "    log_every_n_steps=100,\n",
    "    max_epochs=200,\n",
    "    max_steps=-1,\n",
    "    callbacks=callbacks,\n",
    "    accelerator='gpu', \n",
    "    devices=torch.cuda.device_count(),\n",
    "    strategy=DDPStrategy(find_unused_parameters=False),\n",
    "    reload_dataloaders_every_n_epochs=1\n",
    "    # detect_anomaly=True\n",
    ")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
